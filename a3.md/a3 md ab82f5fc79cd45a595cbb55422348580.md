# a3.md

![a3%20md%20ab82f5fc79cd45a595cbb55422348580/Screen_Shot_2021-03-30_at_5.08.31_AM.png](a3%20md%20ab82f5fc79cd45a595cbb55422348580/Screen_Shot_2021-03-30_at_5.08.31_AM.png)

The above is the screenshot of my tests table. In this project, I tested on 14 test files and for each test file, I recorded 6 cases:

1. its original file size.
2. the size after compressing using LZW.java.
3. the size after compressing using [LZWmod.java](http://lzwmod.java) with resetting dictionary when its full.
4. the size after compressing using [LZWmod.java](http://lzwmod.java) without resetting dictionary when its full.
5. the size after compressing using [LZWmod_extra.java](http://lzwmod.java) which automatically decides whether or not to reset dictionary. 
6. the size after compressing by Mac.

I will analyze these 6 cases for each test file in the following:

1. Lego-big.gif and frosty.jpg:
    - **The WORST COMPRESSION OCCURRED IN IMAGE FILES like gif and jpg.** The file size after compression by LZW compression(including  LZW.java, [LZWmod.java](http://lzwmod.java) ,  [LZWmod_extra.java](http://lzwmod.java)) both become bigger than original file size. The reason is most common image formats (like jpg, png, gif) are already compressed and pictures usually have way larger number of data than txt files and there are more random data, so we cannot get much savings. So when we add more compression on them, the compressed files could even be (slightly) larger because the compression algorithm has no benefit on compressed data since most of the data will not repeat and for each unique data, we created a new one to replace it in LZW, and then the format (eg. gzip) has to add header and/or structure information to the output.
2. code.txt, code2.txt, large.txt, medium.txt, assig2.doc, edit.exe:
    - This six files size after compression by  LZW compression(including  LZW.java, [LZWmod.java](http://lzwmod.java) ,  [LZWmod_extra.java](http://lzwmod.java)) have reduced and their compression ratio is roughly from 1.50-3.00. On average, they are reduced by half. This is because they are all text files. LZW is useful for text files since in text files there are more repeated data so the LZW can replace lots of longer length data with shorter length data. The more duplicate data in files, the higher the compression efficiency the files have. And I noticed that for most of the test files of the six, the LZWmod.java with or without resetting dictionary has the same compression size and they all less than the LZW.java. This is because in LZWmod, I use StringBuilder which saves lots of space.
3. wacky.bmp, winnt256.bmp, gone_fishing.bmp.Z:
    - Although bmp and jpg are both graphic files, bmp files are uncompressed bitmapped images, and jpg are compressed digital images. For compressed files, it is harder to be compressed again. For uncompressed one, things are easier. Especially,  **wacky.bmp** has the **BEST COMPRESSION PERFORMANCE** since the most spaces in that picture is blank. Its compression ratio is over 230. There are just a few words in it. Most of the data are duplicated so LZW can replace them in shorted data.
4. bmps.tar, all.tar, texts.tar: 
    - All the tar files have relatively good compression performance especially the bmps.tar since all the independent bmps files have very good compression performance. The texts.tar compression ratios are similar independent text files. Another thing worth noticing is that for these 3 tars, the compression ratio of [LZWmod.java](http://lzwmod.java) with or without reset and the extra credit one are different. This is because the tar files are all very large and they make use of all the codebook capacity which is 65536 and the codebook need to consider resetting. So the compressed file size will be different. If the codebook decides to reset itself, then the output compressed file will has less size since the codebook occupies less space. The compressed files from extra credit one have larger size than LZWmod.java with reset but smaller size then LZWmod.java without reset because the extra credit one need to monitor(record) the compression ratio and other relative data for deciding whether to reset. This takes some space.
5. Another thing is that I noticed the unix compression has a better performance for almost all the LZW compression files(including  LZW.java, [LZWmod.java](http://lzwmod.java) ,  [LZWmod_extra.java](http://lzwmod.java)) in each test file. Unix compression is based on the LZW compression algorithm but since it is written by those big companies, I guess they wrote it in a longer time and make it perfect. But the difference from mine won't be too big since we all have same LZW algorithms.